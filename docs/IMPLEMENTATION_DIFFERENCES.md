# å®ç°å·®å¼‚è¿½è¸ªæ–‡æ¡£
# Implementation Differences Tracker

> æœ¬æ–‡æ¡£è·Ÿè¸ªä»£ç é‡æ–°å®ç°ä¸åŸå§‹è®ºæ–‡ä¹‹é—´çš„å·®å¼‚ã€‚
> This document tracks differences between our re-implementation and the original paper.

**çŠ¶æ€å›¾ä¾‹ / Legend**:
- âœ… å®Œå…¨å¯¹é½ (Fully Aligned)
- âš ï¸ å­˜åœ¨å·®å¼‚ (Has Differences)
- âŒ æœªå®ç° (Not Implemented)
- ğŸ”„ å¾…éªŒè¯ (Needs Verification)

---

## 1. æ¨¡å‹æ¶æ„ (Model Architecture)

### EEGNet-8,2

| ç»„ä»¶ | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ | å¤‡æ³¨ |
|------|------|--------|------|------|
| F1 (temporal filters) | 8 | 8 | âœ… | |
| D (depth multiplier) | 2 | 2 | âœ… | |
| F2 (pointwise filters) | 16 | 16 | âœ… | |
| kernLength | 32 | 32 | âœ… | |
| Dropoutç±»å‹ | Dropout | Dropout | âœ… | |
| æ¿€æ´»å‡½æ•° | ELU | ELU | âœ… | |
| Pooling | AvgPool (1,4), (1,8) | AvgPool (1,4), (1,8) | âœ… | |
| norm_rate | 0.25 | 0.25 | âœ… | Denseå±‚max_norm |

**ç»“è®º**: æ¨¡å‹æ¶æ„ **å®Œå…¨å¯¹é½**

---

## 2. æ•°æ®é¢„å¤„ç† (Data Preprocessing)

| æ­¥éª¤ | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ | å·®å¼‚è¯´æ˜ |
|------|------|--------|------|----------|
| é‡å‚è€ƒ | CAR | CAR | âœ… | `data - data.mean(axis=1)` |
| ä¸‹é‡‡æ ·ç‡ | 100 Hz | 100 Hz | âœ… | |
| ä¸‹é‡‡æ ·æ–¹æ³• | æœªæ˜ç¡®æŒ‡å®š | scipy.signal.resample | ğŸ”„ | è®ºæ–‡æœªæ˜ç¡®è¯´æ˜æ–¹æ³• |
| å¸¦é€šæ»¤æ³¢èŒƒå›´ | 4-40 Hz | 4-40 Hz | âœ… | |
| æ»¤æ³¢å™¨ç±»å‹ | 4é˜¶Butterworth | 4é˜¶Butterworth | âœ… | |
| æ»¤æ³¢æ–¹æ³• | å› æœæ»¤æ³¢ | lfilter | âœ… | é€‚åˆå®æ—¶å¤„ç† |
| è¾¹ç•Œå¡«å…… | é›¶å¡«å…… | 100ç‚¹é›¶å¡«å…… | âœ… | |
| æ ‡å‡†åŒ– | Z-score | Z-score (axis=2) | âœ… | |
| çª—å£é•¿åº¦ | 1ç§’ | 1ç§’ | âœ… | |
| æ»‘åŠ¨æ­¥é•¿ | 125ms | 128 samples | âœ… | @1024Hz = 125ms |

**ç»“è®º**: æ•°æ®é¢„å¤„ç† **å®Œå…¨å¯¹é½**

---

## 3. è®­ç»ƒå‚æ•° (Training Parameters)

### 3.1 Baseæ¨¡å‹

| å‚æ•° | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ | å·®å¼‚è¯´æ˜ |
|------|------|--------|------|----------|
| Epochs | 300 | 300 | âœ… | |
| Batch size | 16 | 16 | âœ… | |
| Optimizer | Adam | Adam (legacy) | âœ… | TF 2.10å…¼å®¹æ€§ |
| Learning rate | 0.001 | 0.001 | âœ… | |
| Dropout rate | 0.5 | 0.5 | âœ… | |
| Early stopping | patience=80 | patience=80 | âœ… | |
| LR reduction factor | 0.5 | 0.5 | âœ… | |
| LR reduction patience | 30 | 30 | âœ… | |
| Loss | categorical_crossentropy | categorical_crossentropy | âœ… | |
| ç±»åˆ«æƒé‡ | åŠ¨æ€balanced | compute_class_weight('balanced') | âœ… | |

### 3.2 Fine-tunedæ¨¡å‹

| å‚æ•° | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ | å·®å¼‚è¯´æ˜ |
|------|------|--------|------|----------|
| Epochs | 100 | 100 | âœ… | |
| Learning rate | 1e-4 | 1e-4 | âœ… | |
| Dropout rate | æ›´é«˜ | 0.65 | âœ… | è®ºæ–‡æœªç»™å…·ä½“å€¼ |
| å†»ç»“å±‚æ•° | å‰4å±‚ | å‰4å±‚ | âœ… | |
| Early stopping | æœªæ˜ç¡® | patience=30 | ğŸ”„ | è®ºæ–‡æœªæ˜ç¡® |
| LR reduction patience | æœªæ˜ç¡® | patience=15 | ğŸ”„ | è®ºæ–‡æœªæ˜ç¡® |

**ç»“è®º**: è®­ç»ƒå‚æ•° **åŸºæœ¬å¯¹é½**ï¼Œéƒ¨åˆ†ç»†èŠ‚è®ºæ–‡æœªæ˜ç¡®è¯´æ˜

---

## 4. åœ¨çº¿å¹³æ»‘ç®—æ³• (Online Smoothing)

| ç»„ä»¶ | è®ºæ–‡ (Eq. 1) | æœ¬å®ç° | çŠ¶æ€ |
|------|--------------|--------|------|
| åˆå§‹çŠ¶æ€ | hâ‚€ = 0 | `self.h = np.zeros(n_classes)` | âœ… |
| å¹³æ»‘å…¬å¼ | P'â‚œ = Î±Ã—hâ‚œâ‚‹â‚ + Pâ‚œ | `p_prime = alpha * h + current_prob` | âœ… |
| çŠ¶æ€æ›´æ–° | hâ‚œ = P'â‚œ | `self.h = p_prime.copy()` | âœ… |
| å½’ä¸€åŒ– | L2å½’ä¸€åŒ– | `p_prime / np.linalg.norm(p_prime)` | âœ… |
| æ¦‚ç‡å½’ä¸€åŒ– | å’Œä¸º1 | `p_prime / p_prime.sum()` | âœ… |
| é»˜è®¤Î±å€¼ | 0.5 | 0.5 | âœ… |

**ç»“è®º**: åœ¨çº¿å¹³æ»‘ç®—æ³• **å®Œå…¨å¯¹é½**

---

## 5. è¯„ä¼°æ–¹æ³• (Evaluation Methods)

| æŒ‡æ ‡ | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ | ä½ç½® |
|------|------|--------|------|------|
| Majority Voting | âœ“ | âœ“ | âœ… | `evaluation/test_evaluation.py:132-156` |
| Segment Accuracy | âœ“ | âœ“ | âœ… | `evaluation/test_evaluation.py:208` |
| Precision (æ¯ç±») | âœ“ | âœ“ | âœ… | sklearn.metrics |
| Recall (æ¯ç±») | âœ“ | âœ“ | âœ… | sklearn.metrics |
| æ··æ·†çŸ©é˜µ | âœ“ | âœ“ | âœ… | sklearn.metrics |

**ç»“è®º**: è¯„ä¼°æ–¹æ³• **å®Œå…¨å¯¹é½**

---

## 6. å®éªŒè®¾è®¡å·®å¼‚ (Experimental Design Differences)

### 6.1 å·²å®ç°åŠŸèƒ½

| åŠŸèƒ½ | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ |
|------|------|--------|------|
| ç¦»çº¿è®­ç»ƒ | âœ“ | âœ“ | âœ… |
| å•sessionè®­ç»ƒ | âœ“ | âœ“ | âœ… |
| å¤šsessionç´¯ç§¯è®­ç»ƒ | âœ“ | âœ“ | âœ… |
| Fine-tuning | âœ“ | âœ“ | âœ… |
| 5æŠ˜äº¤å‰éªŒè¯ | âœ“ (ç¦»çº¿) | âœ“ | âœ… |
| Majority Votingè¯„ä¼° | âœ“ | âœ“ | âœ… |

### 6.2 éƒ¨åˆ†å®ç°/éœ€è¦å¤–éƒ¨ç¯å¢ƒ

| åŠŸèƒ½ | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ | è¯´æ˜ |
|------|------|--------|------|------|
| BCPy2000å®æ—¶å¤„ç† | âœ“ | æ¡†æ¶ä»£ç å­˜åœ¨ | âš ï¸ | éœ€è¦BCPy2000ç¯å¢ƒ |
| æœºå™¨äººæ‰‹æ§åˆ¶ | âœ“ | æœªåŒ…å« | âŒ | éœ€è¦Allegro Handç¡¬ä»¶ |
| è§†è§‰åé¦ˆç•Œé¢ | âœ“ | æœªåŒ…å« | âŒ | éœ€è¦BCI2000 |

### 6.3 æœªå®ç°åŠŸèƒ½

| åŠŸèƒ½ | è®ºæ–‡ | çŠ¶æ€ | ä¼˜å…ˆçº§ |
|------|------|------|--------|
| ERDåˆ†æ | âœ“ | âŒ | ä½ |
| Saliency Mapç”Ÿæˆ | âœ“ | âŒ | ä½ |
| FBCSP-LDAåŸºçº¿ | âœ“ | âŒ | ä¸­ |
| deepEEGNetå˜ä½“ | Supplementary | âŒ | ä½ |

---

## 7. æ•°æ®æ ¼å¼å·®å¼‚ (Data Format Differences)

| æ–¹é¢ | è®ºæ–‡ | æœ¬å®ç° | çŠ¶æ€ |
|------|------|--------|------|
| EEGé€šé“æ•° | 128 | æ”¯æŒä»»æ„ | âœ… |
| é‡‡æ ·ç‡ | 1024 Hz | ä»æ•°æ®è‡ªåŠ¨è¯»å– | âœ… |
| æ•°æ®æ ¼å¼ | MATLAB .mat | MATLAB .mat | âœ… |
| äº‹ä»¶æ ‡è®° | Target/TrialEnd | Target/TrialEnd | âœ… |
| æ‰‹æŒ‡æ ‡ç­¾ | 1=æ‹‡æŒ‡,2=é£ŸæŒ‡,3=ä¸­æŒ‡,4=å°æŒ‡ | ç›¸åŒ | âœ… |

---

## 8. å·²çŸ¥å·®å¼‚è¯¦æƒ… (Known Differences Details)

### 8.1 TensorFlowç‰ˆæœ¬å…¼å®¹æ€§

**å·®å¼‚**: ä½¿ç”¨`tf.keras.optimizers.legacy.Adam`

**åŸå› **: TensorFlow 2.10å…¼å®¹æ€§è¦æ±‚

**å½±å“**: æ— åŠŸèƒ½å½±å“ï¼Œä»…APIå·®å¼‚

**ä»£ç ä½ç½®**: `Functions.py:348-354`, `training/cross_validation.py:216`

```python
# æœ¬å®ç°
optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)

# TF 2.11+ å¯æ”¹ä¸º
# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
```

### 8.2 Fine-tuning Dropoutç‡

**å·®å¼‚**: è®ºæ–‡æè¿°ä¸º"æ›´é«˜"ï¼Œæœ¬å®ç°ä½¿ç”¨0.65

**åŸå› **: è®ºæ–‡æœªç»™å‡ºå…·ä½“æ•°å€¼

**å½±å“**: å¯èƒ½è½»å¾®å½±å“æ€§èƒ½

**éªŒè¯çŠ¶æ€**: ğŸ”„ éœ€è¦æ•æ„Ÿæ€§åˆ†æ

### 8.3 Early Stopping Patience (Fine-tuning)

**å·®å¼‚**: Fine-tuningä½¿ç”¨patience=30ï¼Œè®ºæ–‡æœªæ˜ç¡®

**åŸå› **: æ ¹æ®epochs=100çš„åˆç†æ¨æ–­

**å½±å“**: å¯èƒ½å½±å“è®­ç»ƒæ”¶æ•›

**éªŒè¯çŠ¶æ€**: ğŸ”„ éœ€è¦éªŒè¯

---

## 9. æ€§èƒ½å¯¹æ¯” (Performance Comparison)

### 9.1 è®ºæ–‡æŠ¥å‘Šæ€§èƒ½

| æ¡ä»¶ | ä»»åŠ¡ | å‡†ç¡®ç‡ |
|------|------|--------|
| MI Session 2 Fine-tuned | 2-class | 80.56% |
| MI Session 2 Fine-tuned | 3-class | 60.61% |
| ME Session 2 Fine-tuned | 2-class | 81.10% |
| ME Session 2 Fine-tuned | 3-class | 60.11% |

### 9.2 æœ¬å®ç°éªŒè¯ç»“æœ

| æ¡ä»¶ | ä»»åŠ¡ | å‡†ç¡®ç‡ | çŠ¶æ€ |
|------|------|--------|------|
| - | - | - | ğŸ”„ å¾…æµ‹è¯• |

> **æ³¨**: éœ€è¦ä½¿ç”¨å…¬å¼€æ•°æ®é›†éªŒè¯å®ç°æ­£ç¡®æ€§

---

## 10. å¾…éªŒè¯é¡¹ç›® (Items to Verify)

### é«˜ä¼˜å…ˆçº§

- [ ] ä½¿ç”¨å…¬å¼€æ•°æ®éªŒè¯ç¦»çº¿è§£ç æ€§èƒ½
- [ ] éªŒè¯fine-tuning dropoutç‡(0.65)çš„å½±å“
- [ ] å¯¹æ¯”5æŠ˜CVç»“æœä¸è®ºæ–‡ç¦»çº¿ç»“æœ

### ä¸­ä¼˜å…ˆçº§

- [ ] å®ç°FBCSP-LDAåŸºçº¿ç”¨äºå¯¹æ¯”
- [ ] éªŒè¯ä¸åŒearly stopping patienceçš„å½±å“

### ä½ä¼˜å…ˆçº§

- [ ] å®ç°ERDåˆ†æè„šæœ¬
- [ ] å®ç°Saliency Mapå¯è§†åŒ–
- [ ] å®ç°deepEEGNetå˜ä½“

---

## 11. å˜æ›´æ—¥å¿— (Changelog)

### v1.0.0 (2025-01-09)
- åˆå§‹æ–‡æ¡£åˆ›å»º
- å®Œæˆè®ºæ–‡æ–¹æ³•ä¸ä»£ç å®ç°çš„å…¨é¢å¯¹æ¯”
- è¯†åˆ«ä¸»è¦å¯¹é½é¡¹å’Œæ½œåœ¨å·®å¼‚

---

## 12. å‚è€ƒæ–‡ä»¶æ˜ å°„ (File Reference Mapping)

| è®ºæ–‡ç« èŠ‚ | å¯¹åº”ä»£ç æ–‡ä»¶ |
|---------|-------------|
| Methods - EEGNet | `EEGModels_tf.py` |
| Methods - Online decoding | `main_online_processing.py` |
| Methods - Preprocessing | `preprocessing/signal_processing.py`, `Functions.py` |
| Methods - Training | `training/cross_validation.py`, `Functions.py` |
| Methods - Smoothing (Eq.1) | `online/online_smoothing.py` |
| Methods - Evaluation | `evaluation/test_evaluation.py` |

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0*
*æœ€åæ›´æ–°: 2025-01-09*
*ç»´æŠ¤è€…: [Project Team]*
